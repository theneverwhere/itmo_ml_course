{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDjH5VgLMPCa"
   },
   "source": [
    "# Задача 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8T7M9eQMRRn"
   },
   "source": [
    "Пусть $X_1, X_2, \\ldots, X_n$ — выборка из экспоненциального распределения с параметром $\\lambda$. Найти оценку максимального правдоподобия параметра $\\lambda$, сравнить ее с байесовской оценкой (MAP и математическое ожидание апостреорного распределения), подобрав сопряженное распределение. Сравнить полученные байесовские оценки с оценкой MLE. Найти предсказательное распределение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab472da",
   "metadata": {},
   "source": [
    "### Решение задачи 1\n",
    "\n",
    "Разбираем экспоненциальную модель: выводим правдоподобие, MLE, байесовские оценки с гамма-приором и предсказательное распределение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47902bb0",
   "metadata": {},
   "source": [
    "**Шаги расчёта**\n",
    "\n",
    "1. Правдоподобие экспоненциальной выборки\n",
    "$$\n",
    " f(x\\mid \\lambda)=\\lambda e^{-\\lambda x},\\qquad L(\\lambda \\mid \\mathbf{x})=\\lambda^n \\exp\\!\\left(-\\lambda\\sum_{i=1}^n x_i\\right).\n",
    "$$\n",
    "Логарифм:\n",
    "$$\n",
    " \\ell(\\lambda)= n\\log \\lambda - \\lambda\\sum_{i=1}^n x_i.\n",
    "$$\n",
    "Максимум достигается при\n",
    "$$\n",
    " \\hat{\\lambda}_{\\text{MLE}}=\\frac{n}{\\sum_{i=1}^n x_i}=\\frac{1}{\\bar x}.\n",
    "$$\n",
    "\n",
    "2. Априорное распределение\n",
    "$$\n",
    " \\lambda \\sim \\Gamma(\\kappa, \\tau), \\qquad \\pi(\\lambda)=\\frac{\\tau^{\\kappa}}{\\Gamma(\\kappa)}\\lambda^{\\kappa-1}e^{-\\tau\\lambda},\\; \\kappa,\\tau>0.\n",
    "$$\n",
    "\n",
    "3. Апостериорное распределение\n",
    "$$\n",
    " \\lambda \\mid \\mathbf{x} \\sim \\Gamma\\big(\\kappa+n,\\; \\tau+\\textstyle\\sum_{i=1}^n x_i\\big).\n",
    "$$\n",
    "\n",
    "4. Байесовские точечные оценки\n",
    "$$\n",
    " \\hat{\\lambda}_{\\text{MAP}}=\\frac{\\kappa+n-1}{\\tau+\\sum x_i},\\qquad\n",
    " \\hat{\\lambda}_{\\text{mean}}=\\mathbb{E}[\\lambda\\mid\\mathbf{x}]=\\frac{\\kappa+n}{\\tau+\\sum x_i}.\n",
    "$$\n",
    "\n",
    "5. Предсказательное распределение для нового значения $y$\n",
    "$$\n",
    " p(y\\mid\\mathbf{x}) = \\int_0^{\\infty} \\lambda e^{-\\lambda y} \\; \\Gamma(\\lambda\\mid\\kappa+n,\\tau+\\sum x_i)\\, d\\lambda =\n",
    " \\frac{(\\kappa+n)\\, (\\tau+\\sum x_i)^{\\kappa+n}}{(y+\\tau+\\sum x_i)^{\\kappa+n+1}}.\n",
    "$$\n",
    "Это распределение Ломакса (Парето второго рода) с тяжёлым хвостом.\n",
    "\n",
    "6. Поведение оценок\n",
    "При малых выборках байесовские оценки тянутся к априорному среднему $\\kappa/\\tau$, а при большом $n$ все подходы сходятся к $1/\\bar x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bce1421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Истинная интенсивность: 0.600\n",
      "MLE: 0.604\n",
      "MAP: 0.604\n",
      "Posterior mean: 0.628\n",
      "90% доверительный интервал для lambda: [0.438, 0.844]\n",
      "Среднее предсказание для нового наблюдения: 1.689\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(7)\n",
    "true_rate = 0.6\n",
    "sample = rng.exponential(scale=1.0 / true_rate, size=25)\n",
    "\n",
    "# Априорные гиперпараметры (shape, rate)\n",
    "kappa0, tau0 = 1.5, 0.8\n",
    "\n",
    "n = sample.size\n",
    "sum_x = sample.sum()\n",
    "\n",
    "lambda_mle = n / sum_x\n",
    "kappa_post = kappa0 + n\n",
    "tau_post = tau0 + sum_x\n",
    "lambda_map = (kappa_post - 1) / tau_post\n",
    "lambda_mean = kappa_post / tau_post\n",
    "\n",
    "# Сэмплы из апостериора (numpy использует scale = 1/rate)\n",
    "posterior_draws = rng.gamma(shape=kappa_post, scale=1.0 / tau_post, size=5000)\n",
    "ci_low, ci_high = np.quantile(posterior_draws, [0.05, 0.95])\n",
    "\n",
    "# Генерируем будущие наблюдения, учитывая неопределённость в lambda\n",
    "lambda_draws = rng.gamma(shape=kappa_post, scale=1.0 / tau_post, size=3000)\n",
    "y_pred = rng.exponential(scale=1.0 / lambda_draws)\n",
    "\n",
    "print(f\"Истинная интенсивность: {true_rate:.3f}\")\n",
    "print(f\"MLE: {lambda_mle:.3f}\")\n",
    "print(f\"MAP: {lambda_map:.3f}\")\n",
    "print(f\"Posterior mean: {lambda_mean:.3f}\")\n",
    "print(f\"90% доверительный интервал для lambda: [{ci_low:.3f}, {ci_high:.3f}]\")\n",
    "print(f\"Среднее предсказание для нового наблюдения: {y_pred.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea596fe",
   "metadata": {},
   "source": [
    "**Итоги задачи 1.** MLE использует только данные и эквивалентен обратному выборочному среднему. Гамма-приор даёт сглаженные MAP/mean оценки и тяжёлохвостое предсказательное распределение: оно реже недооценивает редкие большие времена ожидания, что полезно при малых выборках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WBXJuchMhzE"
   },
   "source": [
    "# Задача 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYWArd6bMjkD"
   },
   "source": [
    "**Мультиномиальное распределение**\n",
    "\n",
    "Пусть проводится серия из $n$ испытаний и в результате каждого испытания происходит ровно одно событие из набора $A_1, A_2, \\dots, A_m$, причем вероятности этих событий равны соответственно $\\mathsf{p}_1, \\mathsf{p}_2, \\dots, \\mathsf{p}_m$, причем\n",
    "$$\\sum_{i=1}^{m}\\mathsf{p}_i = 1.$$\n",
    "\n",
    "Тогда совместное распределение величин $X_1, X_2, \\dots, X_m$, где $X_k$ — число наступлений события $A_k$ в серии из $n$ испытаний, задается вероятностями\n",
    "\n",
    "$$\n",
    "\\mathsf{P}\\left(X_1 = n_1, \\dots, X_m = n_m, \\right) = \\frac{n!}{n_1!\\dots n_m!}\\mathsf{p}_1^{n_1}\\dots \\mathsf{p}_m^{n_m},\n",
    "$$\n",
    "\n",
    "где $n_1, n_2, \\dots, n_m$ — произвольный набор целых неотрицательных чисел, таких что\n",
    "\n",
    "$$\\sum_{i=1}^m n_i = n.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOvNMoSHMrWR"
   },
   "source": [
    "Произведите байесовский вывод для мультиномиального распределения: найдите апостериорное распределение, используя в качестве сопоряженного распределения к правдоподобию [распределение Дирихле](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D0%94%D0%B8%D1%80%D0%B8%D1%85%D0%BB%D0%B5), найдите предсказательное распределение. Объясните результат."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5063f33",
   "metadata": {},
   "source": [
    "### Байесовский вывод для мультиномиальной модели\n",
    "\n",
    "Работаем с набором $m$ категорий. Будем обновлять вероятности исходов при помощи сопряжённого приора Дирихле и строить предсказания для новых экспериментов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff67563",
   "metadata": {},
   "source": [
    "**Формулы**\n",
    "\n",
    "Априор для вектора вероятностей $\\mathbf{p}$:\n",
    "$$\n",
    " \\mathbf{p} \\sim \\mathrm{Dir}(\\alpha_1,\\dots,\\alpha_m), \\quad \\alpha_k>0.\n",
    "$$\n",
    "\n",
    "Правдоподобие наблюдённых счётчиков $\\mathbf{n}=(n_1,\\dots,n_m)$, где $\\sum n_k = n$:\n",
    "$$\n",
    " L(\\mathbf{p}\\mid\\mathbf{n}) \\propto \\prod_{k=1}^m p_k^{n_k}.\n",
    "$$\n",
    "\n",
    "После наблюдений апостериор снова Дирихле:\n",
    "$$\n",
    " \\mathbf{p}\\mid\\mathbf{n} \\sim \\mathrm{Dir}(\\alpha_1+n_1,\\dots,\\alpha_m+n_m).\n",
    "$$\n",
    "\n",
    "Предсказание одного следующего испытания:\n",
    "$$\n",
    " \\mathbb{P}(A_k\\mid\\mathbf{n}) = \\frac{\\alpha_k+n_k}{\\sum_{j=1}^m (\\alpha_j+n_j)}.\n",
    "$$\n",
    "\n",
    "Для пакета из $t$ будущих испытаний с итоговыми счётчиками $\\mathbf{u}$ (\\(\\sum u_k = t\\)) получается распределение Дирихле–мультиномиальное:\n",
    "$$\n",
    " p(\\mathbf{u}\\mid\\mathbf{n}) = \\frac{t!}{\\prod_{k=1}^m u_k!} \\, \\frac{B(\\boldsymbol{\\alpha}+\\mathbf{n}+\\mathbf{u})}{B(\\boldsymbol{\\alpha}+\\mathbf{n})},\n",
    "$$\n",
    "где $B(\\mathbf{a}) = \\dfrac{\\prod_k \\Gamma(a_k)}{\\Gamma(\\sum_k a_k)}$.\n",
    "\n",
    "**Интерпретация**\n",
    "Априорные параметры $\\alpha_k$ работают как псевдосчётчики. Ненулевой $\\alpha_k$ сглаживает нули в данных, а при росте числа наблюдений априорное влияние исчезает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd63a2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Апостериорные параметры: [12.5  5.5  3.5  0.5]\n",
      "Предсказание одного испытания (сглаженные частоты): [0.568 0.25  0.159 0.023]\n",
      "  p1 90% CI: [0.399, 0.735]\n",
      "  p2 90% CI: [0.115, 0.410]\n",
      "  p3 90% CI: [0.055, 0.297]\n",
      "  p4 90% CI: [0.000, 0.088]\n",
      "Вероятность будущего набора [1, 1, 1, 0] (t=3): 0.1189\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import gammaln\n",
    "\n",
    "rng = np.random.default_rng(3)\n",
    "\n",
    "# Априор: слабая уверенность в равномерных вероятностях (по 0.5 псевдосчёта)\n",
    "alpha0 = np.array([0.5, 0.5, 0.5, 0.5])\n",
    "# Наблюдённые количества\n",
    "obs = np.array([12, 5, 3, 0])\n",
    "\n",
    "alpha_post = alpha0 + obs\n",
    "post_mean = alpha_post / alpha_post.sum()\n",
    "\n",
    "# Сэмплинг из апостериора для доверительных интервалов\n",
    "samples_p = rng.dirichlet(alpha_post, size=4000)\n",
    "ci = np.quantile(samples_p, [0.05, 0.95], axis=0)\n",
    "\n",
    "# Предсказание одного опыта\n",
    "pred_one = post_mean\n",
    "\n",
    "# Функция вероятности для будущих t испытаний (Дирихле–мультиномиал)\n",
    "def dirichlet_multinomial_prob(future_counts, alpha):\n",
    "    future_counts = np.asarray(future_counts)\n",
    "    t = future_counts.sum()\n",
    "    term1 = gammaln(t + 1) - gammaln(future_counts + 1).sum()\n",
    "    term2 = gammaln(alpha.sum()) - gammaln(alpha.sum() + t)\n",
    "    term3 = (gammaln(alpha + future_counts) - gammaln(alpha)).sum()\n",
    "    return np.exp(term1 + term2 + term3)\n",
    "\n",
    "future = np.array([1, 1, 1, 0])\n",
    "p_future = dirichlet_multinomial_prob(future, alpha_post)\n",
    "\n",
    "print('Апостериорные параметры:', alpha_post)\n",
    "print('Предсказание одного испытания (сглаженные частоты):', np.round(pred_one, 3))\n",
    "for i, (lo, hi) in enumerate(zip(ci[0], ci[1]), 1):\n",
    "    print(f'  p{i} 90% CI: [{lo:.3f}, {hi:.3f}]')\n",
    "print(f'Вероятность будущего набора {future.tolist()} (t={future.sum()}): {p_future:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa051baa",
   "metadata": {},
   "source": [
    "**Итоги задачи 2.** Обновление Дирихле сводится к сложению параметров с наблюдаемыми счётчиками. Предсказательные вероятности — это сглаженные частоты, которые не дают нулей даже при отсутствующих категориях. Для набора будущих испытаний вероятность задаётся Дирихле–мультиномиалом, объединяющим факториалы и отношения гамма-функций."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
