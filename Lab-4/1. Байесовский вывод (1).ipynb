{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDjH5VgLMPCa"
   },
   "source": [
    "# Задача 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8T7M9eQMRRn"
   },
   "source": [
    "Пусть $X_1, X_2, \\ldots, X_n$ — выборка из экспоненциального распределения с параметром $\\lambda$. Найти оценку максимального правдоподобия параметра $\\lambda$, сравнить ее с байесовской оценкой (MAP и математическое ожидание апостреорного распределения), подобрав сопряженное распределение. Сравнить полученные байесовские оценки с оценкой MLE. Найти предсказательное распределение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab472da",
   "metadata": {},
   "source": [
    "### Решение задачи 1\n",
    "\n",
    "Работаем с экспоненциальным распределением и показываем, чем отличаются оценки: частотная MLE, байесовские MAP и математическое ожидание апостериорного распределения. Ниже все формулы и короткая проверка на игрушечном наборе данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47902bb0",
   "metadata": {},
   "source": [
    "**Аналитические шаги**\n",
    "\n",
    "- Плотность экспоненциального распределения: $p(x \\mid \\lambda) = \\lambda e^{-\\lambda x},\\, x>0$. Правдоподобие выборки $L(\\lambda)=\\lambda^n e^{-\\lambda \\sum x_i}$.\n",
    "- Логарифм: $\\ell(\\lambda)= n\\ln \\lambda - \\lambda \\sum x_i$. Производная и приравнивание к нулю дают оценку максимального правдоподобия $\\hat{\\lambda}_{\text{MLE}} = n/\\sum x_i$.\n",
    "- Сопряжённый приор для параметра интенсивности $\\lambda$ — гамма-распределение $\text{Gamma}(\u0007lpha, \beta)$ (параметризация через `shape` $\u0007lpha$ и `rate` $\beta$): $p(\\lambda)=\tfrac{\beta^{\u0007lpha}}{\\Gamma(\u0007lpha)}\\lambda^{\u0007lpha-1}e^{-\beta\\lambda}$.\n",
    "- Апостериорное распределение после наблюдения выборки остаётся гамма-распределением: $\\lambda \\mid X \\sim \text{Gamma}(\u0007lpha+n, \beta+\\sum x_i)$.\n",
    "- Байесовские оценки: MAP $= \tfrac{\u0007lpha+n-1}{\beta+\\sum x_i}$ (при $\u0007lpha+n>1$ максимум лежит внутри области), математическое ожидание $E[\\lambda\\mid X]=\tfrac{\u0007lpha+n}{\beta+\\sum x_i}$.\n",
    "- Предсказательное распределение для нового наблюдения $y$ получается интегрированием по $\\lambda$: $p(y \\mid X)=\tfrac{\u0007lpha_\text{post}\\, \beta_\text{post}^{\u0007lpha_\text{post}}}{(\beta_\text{post}+y)^{\u0007lpha_\text{post}+1}}$, где $\u0007lpha_\text{post}=\u0007lpha+n$, $\beta_\text{post}=\beta+\\sum x_i$. Это распределение Ломакса; его среднее существует при $\u0007lpha_\text{post}>1$ и равно $\tfrac{\beta_\text{post}}{\u0007lpha_\text{post}-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bce1421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Синтетическая выборка: истинная интенсивность 0.6, берём 20 наблюдений\n",
    "np.random.seed(0)\n",
    "true_lambda = 0.6\n",
    "sample = np.random.exponential(scale=1/true_lambda, size=20)\n",
    "\n",
    "# Параметры гамма-априори (shape, rate)\n",
    "alpha_prior, beta_prior = 2.0, 1.0\n",
    "\n",
    "n = len(sample)\n",
    "sum_x = sample.sum()\n",
    "\n",
    "# Частотная оценка MLE\n",
    "lambda_mle = n / sum_x\n",
    "\n",
    "# Апостериорные параметры\n",
    "alpha_post = alpha_prior + n\n",
    "beta_post = beta_prior + sum_x\n",
    "\n",
    "# Байесовские оценки интенсивности\n",
    "lambda_map = (alpha_post - 1) / beta_post\n",
    "lambda_mean = alpha_post / beta_post\n",
    "\n",
    "# Предсказательная плотность Ломакса на сетке значений\n",
    "y_grid = np.linspace(0, 8, 5)\n",
    "pred_density = (alpha_post * (beta_post ** alpha_post)) / ((beta_post + y_grid) ** (alpha_post + 1))\n",
    "\n",
    "print(f\"Истинное значение интенсивности: {true_lambda:.3f}\")\n",
    "print(f\"MLE: {lambda_mle:.3f}\")\n",
    "print(f\"MAP: {lambda_map:.3f}\")\n",
    "print(f\"Мат. ожидание постериора: {lambda_mean:.3f}\")\n",
    "print('Плотность предсказательного распределения на нескольких точках:')\n",
    "for y, p in zip(y_grid, pred_density):\n",
    "    print(f'  y={y:.1f} -> p(y|X)={p:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea596fe",
   "metadata": {},
   "source": [
    "**Вывод по задаче 1.** При небольшом количестве наблюдений байесовские оценки тянут интенсивность к априорному среднему, что снижает переобучение. MLE игнорирует приор и может сильно колебаться. Предсказательное распределение автоматически учитывает неопределённость по $\\lambda$, распределение хвостатее экспоненциального, поэтому редкие большие значения $y$ получают ненулевую вероятность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WBXJuchMhzE"
   },
   "source": [
    "# Задача 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYWArd6bMjkD"
   },
   "source": [
    "**Мультиномиальное распределение**\n",
    "\n",
    "Пусть проводится серия из $n$ испытаний и в результате каждого испытания происходит ровно одно событие из набора $A_1, A_2, \\dots, A_m$, причем вероятности этих событий равны соответственно $\\mathsf{p}_1, \\mathsf{p}_2, \\dots, \\mathsf{p}_m$, причем\n",
    "$$\\sum_{i=1}^{m}\\mathsf{p}_i = 1.$$\n",
    "\n",
    "Тогда совместное распределение величин $X_1, X_2, \\dots, X_m$, где $X_k$ — число наступлений события $A_k$ в серии из $n$ испытаний, задается вероятностями\n",
    "\n",
    "$$\n",
    "\\mathsf{P}\\left(X_1 = n_1, \\dots, X_m = n_m, \\right) = \\frac{n!}{n_1!\\dots n_m!}\\mathsf{p}_1^{n_1}\\dots \\mathsf{p}_m^{n_m},\n",
    "$$\n",
    "\n",
    "где $n_1, n_2, \\dots, n_m$ — произвольный набор целых неотрицательных чисел, таких что\n",
    "\n",
    "$$\\sum_{i=1}^m n_i = n.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOvNMoSHMrWR"
   },
   "source": [
    "Произведите байесовский вывод для мультиномиального распределения: найдите апостериорное распределение, используя в качестве сопоряженного распределения к правдоподобию [распределение Дирихле](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D0%94%D0%B8%D1%80%D0%B8%D1%85%D0%BB%D0%B5), найдите предсказательное распределение. Объясните результат."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5063f33",
   "metadata": {},
   "source": [
    "### Решение задачи 2\n",
    "\n",
    "Для мультиномиальной модели сопряжённым приором является распределение Дирихле. Оно удобно тем, что параметры приора складываются с фактическими подсчётами и работают как \"псевдонаблюдения\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff67563",
   "metadata": {},
   "source": [
    "**Формулы вывода**\n",
    "\n",
    "- Приор: $\\mathbf{p} \\sim \text{Dir}(\u0007lpha_1, \\dots, \u0007lpha_m)$, где $\u0007lpha_i>0$.\n",
    "- Правдоподобие выборки $\\mathbf{n}=(n_1,\\dots,n_m)$ с $\\sum n_i=n$ пропорционально $\\prod p_i^{n_i}$.\n",
    "- Апостериорное распределение остаётся Дирихле: $\\mathbf{p} \\mid \\mathbf{n} \\sim \text{Dir}(\u0007lpha_1+n_1, \\dots, \u0007lpha_m+n_m)$.\n",
    "- Предсказание одного следующего испытания: $\\mathsf{P}(A_k \\mid \\mathbf{n}) = \tfrac{\u0007lpha_k+n_k}{\\sum_i (\u0007lpha_i+n_i)}$.\n",
    "- Предсказание пакета из $t$ испытаний подчиняется распределению Дирихле–мультиномиальному с плотностью \"комбинацией из факториалов\":\n",
    "$$p(\\mathbf{u} \\mid \\mathbf{n}) = \n",
    "\f",
    "rac{t!}{u_1!\\dots u_m!} \\\n",
    "\f",
    "rac{\\Gamma\\left(\\sum_i (\u0007lpha_i+n_i)\r",
    "ight)}{\\Gamma\\left(t+\\sum_i (\u0007lpha_i+n_i)\r",
    "ight)} \n",
    "\\prod_{i=1}^m \\\n",
    "\f",
    "rac{\\Gamma(\u0007lpha_i+n_i+u_i)}{\\Gamma(\u0007lpha_i+n_i)},$$\n",
    "где $\\mathbf{u}$ — будущие счётчики.\n",
    "- Интерпретация: большие $\u0007lpha_i$ делают распределение более уверенным до наблюдений; нули в данных сглаживаются за счёт псевдосчётчиков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd63a2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import gammaln\n",
    "\n",
    "# Четыре исхода, до наблюдений считаем их равновероятными (по 1 псевдосчёту)\n",
    "alpha_prior = np.array([1., 1., 1., 1.])\n",
    "\n",
    "# Наблюдённые количества событий\n",
    "counts = np.array([12, 5, 3, 0])\n",
    "\n",
    "alpha_post = alpha_prior + counts\n",
    "prob_next = alpha_post / alpha_post.sum()\n",
    "\n",
    "print('Апостериорные параметры Дирихле:', alpha_post)\n",
    "print('Предсказательные вероятности следующего испытания:')\n",
    "for i, p in enumerate(prob_next, 1):\n",
    "    print(f'  P(A{i}) = {p:.3f}')\n",
    "\n",
    "# Пример: вероятность конкретного будущего набора из t=3 испытаний\n",
    "future_counts = np.array([1, 1, 1, 0])\n",
    "t = future_counts.sum()\n",
    "term1 = np.exp(gammaln(t + 1) - gammaln(future_counts + 1).sum())\n",
    "term2 = np.exp(gammaln(alpha_post.sum()) - gammaln(alpha_post.sum() + t))\n",
    "term3 = np.exp((gammaln(alpha_post + future_counts) - gammaln(alpha_post)).sum())\n",
    "p_future = term1 * term2 * term3\n",
    "print(f'Вероятность набора {future_counts.tolist()} для трёх будущих испытаний: {p_future:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa051baa",
   "metadata": {},
   "source": [
    "**Вывод по задаче 2.** Дирихле даёт удобное обновление: новые наблюдения просто добавляются к параметрам. Предсказательные вероятности для новых испытаний совпадают с относительными частотами, сглаженными псевдосчётчиками. Это убирает нули и делает модель устойчивой при маленьких выборках."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
